plot <- reactive({
data() %>%
ggplot() +
geom_sf(aes(fill = n)) +
scale_fill_viridis_c(option = "magma") +
labs(title = input$data) +
theme_void() +
theme(legend.title=element_blank())
})
output$plot <- renderPlot({plot()})
}
shinyApp(ui = ui, server = server)
str(chicago_ward)
server <- function(input, output) {
path <- "~/Desktop/Desktop - MacBook Pro/Data and Programming II/homework-2-frisbiesa/"
rodent <- read_csv(paste0(path, "rodent.csv"))
chicago_ward <- st_read(paste0(path, "Boundaries - Wards (2015-)/geo_export_95df9e80-a2cf-41b8-b65e-55abebbe91df.shp"))
other_311 <- read_csv(paste0(path, "311_Service_Requests_modified.csv"))
df <- reactive({
if (input$data == "rodent"){
dataset <- rodent
}
else if (input$data == "other_311"){
dataset <- other_311
}
})
data <- reactive({
d <- df() %>%
filter(post_lockdown == input$lockdown) %>%
group_by(WARD) %>%
summarise(n = n())
d$WARD <- as.factor(d$WARD)
ward_join <- left_join(chicago_ward, d, by = c("ward" = "WARD"))
})
plot <- reactive({
data() %>%
ggplot() +
geom_sf(aes(fill = n)) +
scale_fill_viridis_c(option = "magma") +
labs(title = input$data) +
theme_void() +
theme(legend.title=element_blank())
})
output$plot <- renderPlot({plot()})
}
shinyApp(ui = ui, server = server)
View(rodent)
other_311 <- other_311 %>%
filter(CREATED_DATE > ymd(20190101))
View(other_311)
##overwriting to decrease load time
write_csv(other_311, path = paste0(path, "311_Service_Requests_modified.csv"))
shinyApp(ui = ui, server = server)
library(tidyverse)
library(shiny)
library(maps)
library(spData)
library(lubridate)
library(rnaturalearth)
library(sp)
install.packages("sf")
install_github("r-spatial/sf")
library(devtools)
install_github("r-spatial/sf")
pkgbuild::check_build_tools(debug = TRUE)
install_github("r-spatial/sf")
brew install pkg-config
brew install gdal
install.packages("sf")
install_github("r-spatial/sf")
library(sp)
library(rnaturalearth)
debt_stock <- read.csv("debt_stock_china.csv") %>%
select(-country_code, -ISO)
setwd("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
debt_stock <- read.csv("debt_stock_china.csv") %>%
select(-country_code, -ISO)
worlde <- world %>%
rename(country = name_long)
mapamundi <- left_join(worlde, debt_stock, by = "country")
ui <- fluidPage(
fluidRow(
column(width = 12,
align = "center",
tags$h1("Evolution of sovereign debt to China",
tags$style('head { face: bold }'))
)
),
fluidRow(
column(width = 12,
align = "center",
sliderInput(inputId = "date",
label = "Date:",
min = 2000 ,
max = 2017,
value = 2000)
),
column(width = 12,
align = "center",
plotOutput("map",
width = "100%")
)
)
)
server <- function(input, output) {
data <- reactive({
mapamundi %>%
filter(year == input$date)
})
output$map <- renderPlot({
ggplot() +
geom_sf(data = world) +
geom_sf(data = data(), aes(fill = china_debt_gdp), alpha = 3/5) +
labs(title = "",
fill = "",
caption = "Source: sonnet") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.caption = element_text(size = 12)) +
guides(color = FALSE,
alpha = FALSE,
fill = guide_colorbar(barwidth = 0.5,
barheight = 10, title.position = "left",
title.theme = element_text(angle = 90),
title.hjust = .5))
},height = 600, width = 600)
}
shinyApp(ui = ui, server = server)
library(tidyverse)
stocks <- read_csv("Homework 3 notebook.csv")
stocks$`VW-Index`<- NULL
stocks$Rf <- NULL
matrix <- cov(stocks)
matrix <- as.matrix(matrix)
weights <- cbind(c(.6,.2,.2),c(.2,.6,.2))
colnames(weights) <- c("A", "B")
rownames(weights) <- c("IBM", "USX", "GM")
var_cov_matrix_portfolios <- t(weights) %*% matrix %*% weights
stocks <- read_csv("Homework 3 notebook.csv")
setwd("~/Desktop/Desktop - MacBook Pro/Investments")
library(tidyverse)
stocks <- read_csv("Homework 3 notebook.csv")
stocks$`VW-Index`<- NULL
stocks$Rf <- NULL
matrix <- cov(stocks)
matrix <- as.matrix(matrix)
weights <- cbind(c(.6,.2,.2),c(.2,.6,.2))
colnames(weights) <- c("A", "B")
rownames(weights) <- c("IBM", "USX", "GM")
var_cov_matrix_portfolios <- t(weights) %*% matrix %*% weights
library(tidytext)
library(docxtractr)
setwd ("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
filenames <- c("Matrix_recommendations_2013.txt", "Matrix_recommendations_2018.txt")
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(gridExtra)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(rvest)
library(purrr)
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
setwd ("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
filenames <- c("Matrix_recommendations_2013.txt", "Matrix_recommendations_2018.txt")
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(textdata)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(readr)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(tidyverse)
library(tidytext)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
##using sentiment list in the function in order to allow for automatic title changing
plot <- function(df){
ggplot(data = sentiment_list[[df]] %>% filter(!is.na(bing))) +
geom_histogram(aes(bing), stat = "count") +
scale_x_discrete(guide= guide_axis(angle = 45)) +
labs(title = df)
}
lapply(names(sentiment_list), plot)
##-----------------------------frequency-----------------------------
freq_list <- list()
for (i in names(sentiment_list)) {
freq_list[[i]] <- count(sentiment_list[[i]], word_tokens, sort = TRUE)
}
freq_list[[2]]
##consider adding "continue" as a positive word
##maybe "consider" or "strengthen" as a negative word?
#--------------------------------------------------------------------------------------------
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2018 <- read_docx("Matrix_recommendations_2018.docx")
recommendations_2018 <- docx_extract_all_tbls(recommendations_2018)
recommendations_2013 %>% head(5)
View(recommendations_2013)
View(recommendations_2013[[1]])
as.tibble(recommendations_2013)
as_tibble(recommendations_2013)
as_tibble(recommendations_2013[[1]])
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
str_replace_all(recommendations_2013$Assessment.comments.on.level.of.implementation, "", NA)
View(recommendations_2018)
str_replace_all(recommendations_2013$Assessment.comments.on.level.of.implementation, "", "NA")
is.na(recommendations_2013$Assessment.comments.on.level.of.implementation) <- recommendations_2013$Assessment.comments.on.level.of.implementation ==""
View(recommendations_2013)
sum(!is.na(recommendations_2013$Assessment.comments.on.level.of.implementation))
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
View(recommendations_2013)
View(recommendations_2013)
View(recommendations_2013)
recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
View(recommendations_2013)
library(reshape2)
install.packages("reshape2")
library(reshape2)
y <- colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
View(y)
View(y)
View(recommendations_2013)
separate(recommendations_2013, Recommendation, into = c("code","recommendations"), remove = FALSE)
test <- separate(recommendations_2013, Recommendation, into = c("code","recommendations"), remove = FALSE)
View(test)
?separate
test <- separate(recommendations_2013, Recommendation, " ", into = c("code","recommendations"), remove = FALSE)
?colsplit
View(y)
cbind(recommendations_2013, y)
?cbind
test <- cbind(recommendations_2013, y)
View(test)
recommendations_2013 <- cbind(recommendations_2013, y)
recommendations_2013$Recommendation <- NULL
View(recommendations_2013)
View(recommendations_2013)
test <- sub("_[^;]+$", "", recommendations_2013$recommendations)
test
test <- sub(";+$", "", recommendations_2013$recommendations)
test
test <- sub(";.*$", "", recommendations_2013$recommendations)
test
recommendations_2013$recommendations <- sub(";.*$", "", recommendations_2013$recommendations)
View(recommendations_2013)
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
##removing all rows which start with "theme"
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
##splitting off first codes
y <-  colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
##binding back together
recommendations_2013 <- cbind(recommendations_2013, y)
##dropping original column
recommendations_2013$Recommendation <- NULL
test <- sub("/([^;]*)$/", "", recommendations_2013$recommendations)
test
test <- sub("(.*)\;", "", recommendations_2013$recommendations)
test <- sub("(.*);", "", recommendations_2013$recommendations)
test
str_extract(recommendations_2013$recommendations, "(.*);")
test <- str_extract(recommendations_2013$recommendations, "(.*);")
test
recommendations_2013$recommendations <- str_extract(recommendations_2013$recommendations, "(.*);")
View(recommendations_2013)
View(recommendations_2013)
View(recommendations_2013)
recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
separate(test_str, sep = ";")
tidyverse::separate(test_str, sep = ";")
tidyverse::separate(test_str, sep = ";")
tidyr::separate(test_str, sep = ";")
?separate
separate(test_str, sep = ";", remove = FALSE)
separate(recommendations_2013$recommendations, sep = ";", remove = FALSE)
separate(recommendations_2013, sep = ";", remove = FALSE)
separate(recommendations_2013, recommendations, sep = ";", remove = FALSE)
separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
View(test)
View(recommendations_2013)
line_49 <- "Develop programme for sharing of its experiences in addressing the right to development with African countries in the context of the Forum on China-Africa cooperation (Sierra Leone)"
recommendations_2013$recommendations %>% count(is.na)
recommendations_2013$recommendations %>% sum(is.na)
recommendations_2013$recommendations %>% sum(is.na())
recommendations_2013 %>% sum(is.na(recommendations))
sum(is.na(recommendations_2013$recommendations))
sum(is.na(recommendations_2013$recommendations))
recommendations_2013$recommendations[,49]
recommendations_2013$recommendations[49,]
recommendations_2013[49,]
recommendations_2013[49,4] <- line_49
View(recommendations_2013)
##finding longest string to test my split
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
View(test)
sum(!is.na(test$e))
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g"), sep = ";", remove = FALSE)
sum(!is.na(test$g))
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i"), sep = ";", remove = FALSE)
sum(!is.na(test$i))
which(sum(!is.na(test$i)))
View(test)
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j"), sep = ";", remove = FALSE)
sum(!is.na(test$i))
sum(!is.na(test$j))
View(test)
test[1:10,]
test_str2 <- test[1:10,]
View(test_str2)
?pivot_longer()
test_str2 %>% pivot_longer(cols = recommendations:j, names_to = NA, values_to = "recommendations", values_drop_na = TRUE)
View(test_str2)
test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE)
test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE) %>% head(5)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE) %>% head(5)
View(test_result)
View(test_str2)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations") %>% head(5)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations") %>% head(15)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations")
View(test_result)
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test_str2 <- test[1:10,]
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations")
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations")
View(test_str2)
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
##finding longest string to test my split
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
test$recommendations <- NULL
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
View(test)
str_replace_na(test, "")
test <- str_replace_na(test, "")
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test[test==""]<-NA
View(test)
test$recommendations <- NULL
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
##testing separating country comments
recommendations_2013 <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
##replacing empty strings with NA
recommendations_2013[recommendations_2013==""]<-NA
recommendations_2013$recommendations <- NULL
test_result <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
recommendations_2013 <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(recommendations_2013)
recommendations_2013$name <- NULL
View(recommendations_2013)
recommendations_2013$country <- str_extract(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
View(recommendations_2013)
?str_extract
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\s*\\([^\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, " \\s*\\([^\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, " \\s*\\([^*\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\([^()]*\\)")
View(recommendations_2013)
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
##removing all rows which start with "theme"
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
##splitting off first codes
y <-  colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
##binding back together
recommendations_2013 <- cbind(recommendations_2013, y)
##dropping original column
recommendations_2013$Recommendation <- NULL
##use regex to remove ending redundant information from recommendations
##Source: https://r4ds.had.co.nz/strings.html
recommendations_2013$recommendations <- str_extract(recommendations_2013$recommendations, "(.*);")
##found one instance where a typo in punctuation removed the string
sum(is.na(recommendations_2013$recommendations))
##adding back in
line_49 <- "Develop programme for sharing of its experiences in addressing the right to development with African countries in the context of the Forum on China-Africa cooperation (Sierra Leone)"
recommendations_2013[49,4] <- line_49
##testing separating country comments
recommendations_2013 <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
##replacing empty strings with NA
recommendations_2013[recommendations_2013==""]<-NA
recommendations_2013$recommendations <- NULL
recommendations_2013 <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
recommendations_2013$name <- NULL
?str_extract
recommendations_2013$country <- str_extract(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\([^()]*\\)")
View(recommendations_2013)
