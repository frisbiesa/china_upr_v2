<<<<<<< HEAD
plot <- reactive({
data() %>%
ggplot() +
geom_sf(aes(fill = n)) +
scale_fill_viridis_c(option = "magma") +
labs(title = input$data) +
theme_void() +
theme(legend.title=element_blank())
})
output$plot <- renderPlot({plot()})
=======
summarise(promedio = mean(acceso_x100hab)) %>%
ggplot() +
geom_line(aes(anio, promedio, color = provincia), size = 1.2)+
gghighlight(provincia == "Tierra Del Fuego", unhighlighted_params = list(size = 0.75), label_params = list(vjust =-1.5)) +
scale_x_continuous(breaks = 2014:2020) +
labs(y = "Internet access per 100 habitants", x = "Year", title = "Internet access") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(eph)
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2018_2019.rds") %>%
organize_labels(., type='individual')
View(base)
base <- get_microdata(year = 2004:2019,
trimester = 1,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2018_2019.rds") %>%
organize_labels(., type='individual')
View(base)
base %>%
select(microdata) %>%
unnest(microdata)
base <- get_microdata(year = 2004:2019,
trimester = 1,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2004_2019.rds") %>%
organize_labels(., type='individual')
base %>%
select(microdata) %>%
unnest(microdata)
base %>%
select(microdata) %>%
unnest(microdata)
base %>%
select(microdata) %>%
unnest(microdata)
View(base)
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2004_2019.rds") %>%
organize_labels(., type='individual')
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2004_2019.rds") %>%
organize_labels(., type='individual')
base %>%
select(microdata) %>%
unnest(microdata)
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES'),
destfile = "base_2004_2019.rds") %>%
organize_labels(., type='individual')
View(base)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(eph)
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual', destfile = 'bases_eph.rds')
base_org <- organize_labels(base, type = 'individual')
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_CAES', 'CH15', 'CH15_Cod'), window='anual')
pool <- organize_panels(bases=base_org$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_CAES', 'CH15', 'CH15_Cod'), window='anual')
lista_bases <- list(toybase_individual_2016_03,toybase_individual_2016_04)
lista_bases <- list(toybase_individual_2016_03,toybase_individual_2016_04)
lista_bases <- list(toybase_individual_2016_03,toybase_individual_2016_04)
pool <- organize_panels(bases=base_org$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_CAES', 'CH15', 'CH15_Cod'), window='anual')
gc()
pool <- organize_panels(bases=base_org$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_CAES', 'CH15', 'CH15_Cod'), window='anual')
?organize_panels
?organize_panels
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(eph)
base <- get_microdata(year = 2004:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_COD'),
destfile = "base_2004_2019.rds") %>%
organize_labels(., type='individual')
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_COD', 'CH15', 'CH15_Cod'), window='anual')
base <- get_microdata(year = 2005:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_COD')) %>%
organize_labels(., type='individual')
base <- get_microdata(year = 2005:2019,
trimester = 1:4,
type='individual',
vars =c('ANO4', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_COD')) %>%
organize_labels(., type='individual')
base %>%
select(microdata) %>%
unnest(microdata)
base %>%
select(microdata) %>%
unnest(microdata)
base <- get_microdata(year = 2010:2019,
trimester = 1:4,
type='individual',
vars =c('ANO4', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_COD')) %>%
organize_labels(., type='individual')
?connections
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(eph)
base <- get_microdata(year = 2010:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06', 'CH15', 'CH15_Cod',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_COD')) %>%
organize_labels(., type='individual')
base <- get_microdata(year = 2010:2019,
trimester = 1:4,
type='individual') %>%
organize_labels(., type='individual')
base %>%
select(microdata) %>%
unnest(microdata)
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B_COD', 'CH15', 'CH15_Cod'), window='anual')
base <- get_microdata(year = 2010:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO')) %>%
organize_labels(., type='individual')
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO'), window='anual')
pool_tdf <- pool %>%
filter(AGLOMERADO == 31)
## esta complicado el tema
pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE)) %>%
ggplot +
geom_line(aes(ANO4, univ_publico), stat = "identity")
## esta complicado el tema
pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE), pop = sum(PONDERA), ocup = sum(PONDERA[ESTADO == 1]), tasa_ocup = ocup/pop) %>%
ggplot +
geom_line(aes(ANO4, univ_publico), stat = "identity") +
geom_line(aes(ANO4, tasa_ocup), stat = "identity")
## esta complicado el tema
pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE), pop = sum(PONDERA), ocup = sum(PONDERA[ESTADO == 1]), tasa_ocup = ocup/pop, univ_privado = sum(PONDERA[PP04A==2 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==2 & NIVEL_ED == 6], na.rm = TRUE)) %>%
ggplot +
geom_line(aes(ANO4, univ_publico), stat = "identity") +
geom_line(aes(ANO4, univ_privado), stat = "identity")
## esta complicado el tema
pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE), pop = sum(PONDERA), ocup = sum(PONDERA[ESTADO == 1]), tasa_ocup = ocup/pop, univ_privado = sum(PONDERA[PP04A==2 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==2 & NIVEL_ED == 6], na.rm = TRUE)) %>%
ggplot +
geom_line(aes(ANO4, univ_privado), stat = "identity")
trabajo <- pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE),
pop = sum(PONDERA), ocup = sum(PONDERA[ESTADO == 1]),
tasa_ocup = ocup/pop,
univ_privado = sum(PONDERA[PP04A==2 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==2 & NIVEL_ED == 6], na.rm = TRUE))
View(trabajo)
## esta complicado el tema
trabajo <- pool_tdf %>%
group_by(ANO4) %>%
summarise(univ_publico = sum(PONDERA[PP04A==1 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE),
pop = sum(PONDERA), ocup = sum(PONDERA[ESTADO == 1]),
tasa_ocup = ocup/pop,
univ_privado = sum(PONDERA[PP04A==2 & NIVEL_ED == 6], na.rm = TRUE)/sum(PONDERA[ESTADO==1 & NIVEL_ED == 6], na.rm = TRUE))
pool_tdf %>%
group_by(ANO4, PP04A, NIVEL_ED) %>%
summarise(total = sum(PONDERA[NIVEL_ED == 6]))
pool_tdf %>%
group_by(ANO4) %>%
summarise(total = sum(PONDERA[NIVEL_ED == 6]))
pool_tdf %>%
group_by(ANO4) %>%
summarise(total_priv =  sum(PONDERA[PP04A == 2]),
univ_priv = sum(PONDERA[NIVEL_ED == 6 & PP04A == 2]),
tasa = univ_priv/total_priv)
pool_tdf %>%
group_by(ANO4) %>%
summarise(total_priv =  sum(PONDERA[PP04A == 2], na.rm = TRUE),
univ_priv = sum(PONDERA[NIVEL_ED == 6 & PP04A == 2], na.rm = TRUE),
tasa = univ_priv/total_priv)
base <- get_microdata(year = 2008:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B COD')) %>%
organize_labels(., type='individual')
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B COD'), window='anual')
base <- get_microdata(year = 2008:2019,
trimester = 1:4,
type='individual',
vars =c('CODUSU','NRO_HOGAR','COMPONENTE','ANO4',
'TRIMESTRE','CH04','CH06',
'PONDERA','ESTADO','PP04A',
'NIVEL_ED','AGLOMERADO', 'PP04B_CAES')) %>%
organize_labels(., type='individual')
pool <- organize_panels(bases=base$microdata, variables=c('PONDERA','ESTADO','PP04A', 'NIVEL_ED', 'AGLOMERADO', 'PP04B COD'), window='anual')
individual
toybase_individual_2016_03
git lfs install
write_sf(mex_muns, "Muni_2012gw.shp")
library(sf)
write_sf(mex_muns, "Muni_2012gw.shp")
mex_muns$MUN_ID <- str_c(mex_muns$CVE_ENT, mex_muns$CVE_MUN)
library(tidyverse)
library(jsonlite)
library(sf)
mexico_eci <- read.csv("ECI.csv")
library(tidyverse)
library(jsonlite)
library(httr)
library(sf)
mexico_eci <- read.csv("ECI.csv")
mexico_eci <- mexico_eci %>%
rename(mun_id = 1, eci = 2, municipality = 3)
mexico_eci <- mexico_eci %>%
mutate(mun_id = str_pad(mun_id, width = 5, pad = "0"))
write.csv(mexico_eci, "eci2.csv")
mex_muns <- read_sf("Muni_2012gw.shp")
mex_muns$MUN_ID <- str_c(mex_muns$CVE_ENT, mex_muns$CVE_MUN)
write_sf(mex_muns, "Muni_2012gw.shp")
library(tidyverse)
library(jsonlite)
library(httr)
library(sf)
mexico_eci <- read.csv("ECI.csv")
mexico_eci <- mexico_eci %>%
rename(mun_id = 1, eci = 2, municipality = 3)
mexico_eci <- mexico_eci %>%
mutate(mun_id = str_pad(mun_id, width = 5, pad = "0"))
write.csv(mexico_eci, "eci2.csv")
mex_muns <- read_sf("Muni_2012gw.shp")
mex_muns$MUN_ID <- str_c(mex_muns$CVE_ENT, mex_muns$CVE_MUN)
write_sf(mex_muns, "Muni_2012gw.shp")
library(tidyverse)
library(shiny)
install.packages("digest")
install.packages("digest")
library(digest)
library(shiny)
library(shiny)
uninstall.package(digest)
uninstall.packages(digest)
remove.packages(digest)
remove.packages(digest)
remove.packages("digest")
devtools::install("digest")
install.packages("digest")
install.packages("digest")
remove.packages("digest")
install.packages(c("anytime", "attempt", "backports", "bayesplot", "BH", "bibtex", "bit", "bit64", "bookdown", "broom", "callr", "car", "carData", "choroplethr", "chron", "cli", "clipr", "coda", "colorspace", "colourpicker", "covr", "cowplot", "cpp11", "crayon", "crosstalk", "DBI", "dbplyr", "devtools", "dials", "dplyr", "DT", "e1071", "ellipsis", "ergm", "expss", "fansi", "fastmap", "flexmix", "forcats", "foreach", "Formula", "fredr", "fs", "furrr", "future", "gdtools", "generics", "gganimate", "gghighlight", "ggplot2", "ggpubr", "ggrepel", "ggridges", "gh", "git2r", "globals", "glue", "gmp", "gower", "hardhat", "haven", "hexbin", "hipread", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "httr", "hunspell", "igraph", "infer", "inline", "insight", "ipumsr", "isoband", "ISOcodes", "iterators", "janitor", "jsonlite", "jtools", "knitr", "labeling", "labelled", "Lahman", "later", "lava", "leaflet", "lhs", "lme4", "lmtest", "loo", "lubridate", "magick", "magrittr", "maptools", "margins", "MatchIt", "matrixStats", "maxLik", "memisc", "memoise", "modelr", "naniar", "network", "nloptr", "openssl", "openxlsx", "parsnip", "patchwork", "pbkrtest", "permutations", "pillar", "pkgbuild", "pkgload", "plm", "pROC", "processx", "promises", "ps", "purrr", "quantreg", "questionr", "R.methodsS3", "R.oo", "R.utils", "R6", "rappdirs", "raster", "Rcpp", "RcppEigen", "RcppParallel", "Rdpack", "recipes", "rematch2", "remotes", "repr", "reprex", "reshape2", "rex", "rgdal", "rgeos", "rlang", "rmarkdown", "RMySQL", "robustbase", "roxygen2", "rprojroot", "rsample", "RSQLite", "rstan", "rstanarm", "rstantools", "rstatix", "rstudioapi", "rversions", "rvest", "sampling", "sandwich", "sf", "shinyjs", "shinythemes", "sjlabelled", "sp", "SQUAREM", "StanHeaders", "statar", "statmod", "statnet.common", "stopwords", "stringi", "sys", "systemfonts", "testthat", "tibble", "tidycensus", "tidymodels", "tidyposterior", "tidypredict", "tidyr", "tidytext", "tigris", "tinytex", "tune", "units", "usethis", "vctrs", "vroom", "WDI", "withr", "workflows", "writexl", "xfun", "xml2", "xts", "yardstick", "zip", "zoo"))
library(shiny)
library(tidyverse)
library(dplyr)
library(tidyverse)
install.packages("dplyr")
install.packages("dplyr")
llibrary(dplyr)
library(dplyr)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
update.packages(ask = FALSE)
use warnings()
warnings()
library(tidyverse)
shiny::runApp('C:/Users/nico/Desktop/Harris/Winter 2021/Data Programming II/Fortunato-Frisbie-final-project')
install.packages("devtools")
runApp('C:/Users/nico/Desktop/Harris/Winter 2021/Data Programming II/Fortunato-Frisbie-final-project')
setwd("C:/Users/nico/Desktop/Harris/Winter 2021/Data Programming II/Fortunato-Frisbie-final-project")
runApp()
setwd("C:/Users/nico/Desktop/Harris/Winter 2021/Data Programming II/Fortunato-Frisbie-final-project")
runApp()
debt_stock <- read.csv("debt_stock_china.csv") %>%
select(-country_code, -ISO)
worlde <- world %>%
rename(country = name_long)
mapamundi <- left_join(worlde, debt_stock, by = "country")
mapamundi$debt_usd <- str_remove_all(mapamundi$debt_usd, ",")
mapamundi$debt_usd <- as.numeric(mapamundi$debt_usd)
ui <- fluidPage(
fluidRow(
column(width = 12,
align = "center",
tags$h1("Evolution of sovereign debt to China",
tags$style('head { face: bold }'))
)
),
fluidRow(
column(width = 6,
align = "center",
sliderInput(inputId = "date",
label = "Date:",
min = 2000 ,
max = 2017,
value = 2000)
)
,
column(width = 6,
selectInput(inputId = "fill",
label = "select variable",
c("aggregate debt" = "debt_usd",
"debt to GDP" = "china_debt_gdp"))
),
fluidRow(
column(width = 12,
align = "center",
plotlyOutput("map",
width = "100%")
)
)
)
)
library(plotly)
install.packages("plotly")
install.packages("plotly")
install.packages("shinyWidgets")
library(shinyWidgets)
ui <- fluidPage(
fluidRow(
column(width = 12,
align = "center",
tags$h1("Evolution of sovereign debt to China",
tags$style('head { face: bold }'))
)
),
fluidRow(
column(width = 6,
align = "center",
sliderInput(inputId = "date",
label = "Date:",
min = 2000 ,
max = 2017,
value = 2000)
)
,
column(width = 6,
selectInput(inputId = "fill",
label = "select variable",
c("aggregate debt" = "debt_usd",
"debt to GDP" = "china_debt_gdp"))
),
fluidRow(
column(width = 12,
align = "center",
plotlyOutput("map",
width = "100%")
)
)
)
)
server <- function(input, output) {
data <- reactive({
mapamundi %>%
filter(year == input$date) %>%
rename(graph_variable = input$fill)
})
scale <- reactive({
if (input$fill == "debt_usd"){
s <- c(1, 200000000)
}
else if (input$fill == "china_debt_gdp"){
s <- c(1, 30)
}
})
plot <- reactive({
plt <- ggplot() +
geom_sf(data = world) +
geom_sf(data = data(),
aes(group = year, fill = graph_variable),
alpha = 3/5) +
labs(title = "",
fill = "",
caption = 'Source: "China’s Overseas Lending," NBER, Sebastian Horn, Carmen M. Reinhart & Christoph Trebesch') +
scale_fill_viridis_c(option = "magma", limits = scale()) +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.caption = element_text(size = 12))+
guides(color = FALSE, alpha = FALSE,
fill = guide_colorbar(barwidth = 0.5,
barheight = 10, title.position = "left",
title.theme = element_text(angle = 90),
title.hjust = .5))
plt <- ggplotly(plt, tooltip= c("country", "fill"))
})
output$map <- renderPlotly({plot()})
}
shinyApp(ui = ui, server = server)
mapamundi <- left_join(worlde, debt_stock, by = "country")
mapamundi$debt_usd <- str_remove_all(mapamundi$debt_usd, ",")
mapamundi$debt_usd <- as.numeric(mapamundi$debt_usd)
ui <- fluidPage(
fluidRow(
column(width = 12,
align = "center",
tags$h1("Evolution of sovereign debt to China",
tags$style('head { face: bold }'))
)
),
fluidRow(
column(width = 6,
align = "center",
sliderInput(inputId = "date",
label = "Date:",
min = 2000 ,
max = 2017,
value = 2000)
)
,
column(width = 6,
selectInput(inputId = "fill",
label = "select variable",
c("aggregate debt" = "debt_usd",
"debt to GDP" = "china_debt_gdp"))
),
fluidRow(
column(width = 12,
align = "center",
plotlyOutput("map",
width = "100%")
)
)
)
)
server <- function(input, output) {
data <- reactive({
mapamundi %>%
filter(year == input$date) %>%
rename(graph_variable = input$fill)
})
scale <- reactive({
if (input$fill == "debt_usd"){
s <- c(1, 200000000)
>>>>>>> e231585f6bf8943abb1589d672e585dbc8fbf09f
}
else if (input$fill == "china_debt_gdp"){
s <- c(1, 30)
}
})
plot <- reactive({
plt <- ggplot() +
geom_sf(data = world) +
geom_sf(data = data(),
aes(group = year, fill = graph_variable),
alpha = 3/5) +
labs(title = "",
fill = "",
caption = 'Source: "China’s Overseas Lending," NBER, Sebastian Horn, Carmen M. Reinhart & Christoph Trebesch') +
scale_fill_viridis_c(option = "magma", limits = scale()) +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.caption = element_text(size = 12))+
guides(color = FALSE, alpha = FALSE,
fill = guide_colorbar(barwidth = 0.5,
barheight = 10, title.position = "left",
title.theme = element_text(angle = 90),
title.hjust = .5))
plt <- ggplotly(plt, tooltip= c("country", "fill"))
})
output$map <- renderPlotly({plot()})
}
shinyApp(ui = ui, server = server)
<<<<<<< HEAD
View(rodent)
other_311 <- other_311 %>%
filter(CREATED_DATE > ymd(20190101))
View(other_311)
##overwriting to decrease load time
write_csv(other_311, path = paste0(path, "311_Service_Requests_modified.csv"))
shinyApp(ui = ui, server = server)
library(tidyverse)
library(shiny)
library(maps)
library(spData)
library(lubridate)
library(rnaturalearth)
library(sp)
install.packages("sf")
install_github("r-spatial/sf")
library(devtools)
install_github("r-spatial/sf")
pkgbuild::check_build_tools(debug = TRUE)
install_github("r-spatial/sf")
brew install pkg-config
brew install gdal
install.packages("sf")
install_github("r-spatial/sf")
library(sp)
library(rnaturalearth)
debt_stock <- read.csv("debt_stock_china.csv") %>%
select(-country_code, -ISO)
setwd("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
debt_stock <- read.csv("debt_stock_china.csv") %>%
select(-country_code, -ISO)
worlde <- world %>%
rename(country = name_long)
mapamundi <- left_join(worlde, debt_stock, by = "country")
ui <- fluidPage(
fluidRow(
column(width = 12,
align = "center",
tags$h1("Evolution of sovereign debt to China",
tags$style('head { face: bold }'))
)
),
fluidRow(
column(width = 12,
align = "center",
sliderInput(inputId = "date",
label = "Date:",
min = 2000 ,
max = 2017,
value = 2000)
),
column(width = 12,
align = "center",
plotOutput("map",
width = "100%")
)
)
)
server <- function(input, output) {
data <- reactive({
mapamundi %>%
filter(year == input$date)
})
output$map <- renderPlot({
ggplot() +
geom_sf(data = world) +
geom_sf(data = data(), aes(fill = china_debt_gdp), alpha = 3/5) +
labs(title = "",
fill = "",
caption = "Source: sonnet") +
theme_minimal() +
theme(axis.text.x = element_blank(),
axis.text.y = element_blank(),
plot.caption = element_text(size = 12)) +
guides(color = FALSE,
alpha = FALSE,
fill = guide_colorbar(barwidth = 0.5,
barheight = 10, title.position = "left",
title.theme = element_text(angle = 90),
title.hjust = .5))
},height = 600, width = 600)
}
shinyApp(ui = ui, server = server)
library(tidyverse)
stocks <- read_csv("Homework 3 notebook.csv")
stocks$`VW-Index`<- NULL
stocks$Rf <- NULL
matrix <- cov(stocks)
matrix <- as.matrix(matrix)
weights <- cbind(c(.6,.2,.2),c(.2,.6,.2))
colnames(weights) <- c("A", "B")
rownames(weights) <- c("IBM", "USX", "GM")
var_cov_matrix_portfolios <- t(weights) %*% matrix %*% weights
stocks <- read_csv("Homework 3 notebook.csv")
setwd("~/Desktop/Desktop - MacBook Pro/Investments")
library(tidyverse)
stocks <- read_csv("Homework 3 notebook.csv")
stocks$`VW-Index`<- NULL
stocks$Rf <- NULL
matrix <- cov(stocks)
matrix <- as.matrix(matrix)
weights <- cbind(c(.6,.2,.2),c(.2,.6,.2))
colnames(weights) <- c("A", "B")
rownames(weights) <- c("IBM", "USX", "GM")
var_cov_matrix_portfolios <- t(weights) %*% matrix %*% weights
library(tidytext)
library(docxtractr)
setwd ("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
filenames <- c("Matrix_recommendations_2013.txt", "Matrix_recommendations_2018.txt")
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(gridExtra)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(rvest)
library(purrr)
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
setwd ("~/Desktop/Desktop - MacBook Pro/Data and Programming II/final project/Fortunato-Frisbie-final-project")
filenames <- c("Matrix_recommendations_2013.txt", "Matrix_recommendations_2018.txt")
sentiment_list <- list()
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(textdata)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(readr)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
library(tidyverse)
library(tidytext)
for (i in filenames) {
s <- read_file(i)
text_df <- tibble(text = s)
word_tokens_df <- unnest_tokens(text_df, word_tokens,  text, token = "words")
df <- anti_join(word_tokens_df, stop_words, by = c("word_tokens" = "word"))
df$word_tokens <- removeNumbers(df$word_tokens)
df$word_tokens <-  removePunctuation(df$word_tokens)
df <- df %>% filter(word_tokens != "")
for (s in c("nrc", "afinn", "bing")) {
df <- df %>%
left_join(get_sentiments(s), by = c("word_tokens" = "word")) %>%
plyr::rename(replace = c(sentiment = s, value = s), warn_missing = FALSE)
}
sentiment_list <- append(sentiment_list, list(df))
}
names(sentiment_list) <- c("Comments About China in 2013", "Comments About China in 2018") # Define names of df's
##using sentiment list in the function in order to allow for automatic title changing
plot <- function(df){
ggplot(data = sentiment_list[[df]] %>% filter(!is.na(bing))) +
geom_histogram(aes(bing), stat = "count") +
scale_x_discrete(guide= guide_axis(angle = 45)) +
labs(title = df)
}
lapply(names(sentiment_list), plot)
##-----------------------------frequency-----------------------------
freq_list <- list()
for (i in names(sentiment_list)) {
freq_list[[i]] <- count(sentiment_list[[i]], word_tokens, sort = TRUE)
}
freq_list[[2]]
##consider adding "continue" as a positive word
##maybe "consider" or "strengthen" as a negative word?
#--------------------------------------------------------------------------------------------
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2018 <- read_docx("Matrix_recommendations_2018.docx")
recommendations_2018 <- docx_extract_all_tbls(recommendations_2018)
recommendations_2013 %>% head(5)
View(recommendations_2013)
View(recommendations_2013[[1]])
as.tibble(recommendations_2013)
as_tibble(recommendations_2013)
as_tibble(recommendations_2013[[1]])
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
str_replace_all(recommendations_2013$Assessment.comments.on.level.of.implementation, "", NA)
View(recommendations_2018)
str_replace_all(recommendations_2013$Assessment.comments.on.level.of.implementation, "", "NA")
is.na(recommendations_2013$Assessment.comments.on.level.of.implementation) <- recommendations_2013$Assessment.comments.on.level.of.implementation ==""
View(recommendations_2013)
sum(!is.na(recommendations_2013$Assessment.comments.on.level.of.implementation))
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
View(recommendations_2013)
View(recommendations_2013)
View(recommendations_2013)
recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
View(recommendations_2013)
library(reshape2)
install.packages("reshape2")
library(reshape2)
y <- colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
View(y)
View(y)
View(recommendations_2013)
separate(recommendations_2013, Recommendation, into = c("code","recommendations"), remove = FALSE)
test <- separate(recommendations_2013, Recommendation, into = c("code","recommendations"), remove = FALSE)
View(test)
?separate
test <- separate(recommendations_2013, Recommendation, " ", into = c("code","recommendations"), remove = FALSE)
?colsplit
View(y)
cbind(recommendations_2013, y)
?cbind
test <- cbind(recommendations_2013, y)
View(test)
recommendations_2013 <- cbind(recommendations_2013, y)
recommendations_2013$Recommendation <- NULL
View(recommendations_2013)
View(recommendations_2013)
test <- sub("_[^;]+$", "", recommendations_2013$recommendations)
test
test <- sub(";+$", "", recommendations_2013$recommendations)
test
test <- sub(";.*$", "", recommendations_2013$recommendations)
test
recommendations_2013$recommendations <- sub(";.*$", "", recommendations_2013$recommendations)
View(recommendations_2013)
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
##removing all rows which start with "theme"
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
##splitting off first codes
y <-  colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
##binding back together
recommendations_2013 <- cbind(recommendations_2013, y)
##dropping original column
recommendations_2013$Recommendation <- NULL
test <- sub("/([^;]*)$/", "", recommendations_2013$recommendations)
test
test <- sub("(.*)\;", "", recommendations_2013$recommendations)
test <- sub("(.*);", "", recommendations_2013$recommendations)
test
str_extract(recommendations_2013$recommendations, "(.*);")
test <- str_extract(recommendations_2013$recommendations, "(.*);")
test
recommendations_2013$recommendations <- str_extract(recommendations_2013$recommendations, "(.*);")
View(recommendations_2013)
View(recommendations_2013)
View(recommendations_2013)
recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
separate(test_str, sep = ";")
tidyverse::separate(test_str, sep = ";")
tidyverse::separate(test_str, sep = ";")
tidyr::separate(test_str, sep = ";")
?separate
separate(test_str, sep = ";", remove = FALSE)
separate(recommendations_2013$recommendations, sep = ";", remove = FALSE)
separate(recommendations_2013, sep = ";", remove = FALSE)
separate(recommendations_2013, recommendations, sep = ";", remove = FALSE)
separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
View(test)
View(recommendations_2013)
line_49 <- "Develop programme for sharing of its experiences in addressing the right to development with African countries in the context of the Forum on China-Africa cooperation (Sierra Leone)"
recommendations_2013$recommendations %>% count(is.na)
recommendations_2013$recommendations %>% sum(is.na)
recommendations_2013$recommendations %>% sum(is.na())
recommendations_2013 %>% sum(is.na(recommendations))
sum(is.na(recommendations_2013$recommendations))
sum(is.na(recommendations_2013$recommendations))
recommendations_2013$recommendations[,49]
recommendations_2013$recommendations[49,]
recommendations_2013[49,]
recommendations_2013[49,4] <- line_49
View(recommendations_2013)
##finding longest string to test my split
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e"), sep = ";", remove = FALSE)
View(test)
sum(!is.na(test$e))
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g"), sep = ";", remove = FALSE)
sum(!is.na(test$g))
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i"), sep = ";", remove = FALSE)
sum(!is.na(test$i))
which(sum(!is.na(test$i)))
View(test)
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j"), sep = ";", remove = FALSE)
sum(!is.na(test$i))
sum(!is.na(test$j))
View(test)
test[1:10,]
test_str2 <- test[1:10,]
View(test_str2)
?pivot_longer()
test_str2 %>% pivot_longer(cols = recommendations:j, names_to = NA, values_to = "recommendations", values_drop_na = TRUE)
View(test_str2)
test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE)
test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE) %>% head(5)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations", values_drop_na = TRUE) %>% head(5)
View(test_result)
View(test_str2)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations") %>% head(5)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations") %>% head(15)
test_result <- test_str2 %>% pivot_longer(cols = recommendations:j, values_to = "recommendations")
View(test_result)
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test_str2 <- test[1:10,]
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations")
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations")
View(test_str2)
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
##finding longest string to test my split
test_str <- recommendations_2013$recommendations[which.max(nchar(recommendations_2013$recommendations))]
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
test$recommendations <- NULL
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
View(test)
str_replace_na(test, "")
test <- str_replace_na(test, "")
##testing separating country comments
test <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
test[test==""]<-NA
View(test)
test$recommendations <- NULL
test_str2 <- test[1:10,]
?pivot_longer()
test_result <- test_str2 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
##testing separating country comments
recommendations_2013 <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
##replacing empty strings with NA
recommendations_2013[recommendations_2013==""]<-NA
recommendations_2013$recommendations <- NULL
test_result <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(test_result)
recommendations_2013 <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
View(recommendations_2013)
recommendations_2013$name <- NULL
View(recommendations_2013)
recommendations_2013$country <- str_extract(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
View(recommendations_2013)
?str_extract
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\s*\\([^\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, " \\s*\\([^\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, " \\s*\\([^*\\)]+\\)")
View(recommendations_2013)
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\([^()]*\\)")
View(recommendations_2013)
recommendations_2013 <- read_docx("Matrix_recommendations_2013.docx")
recommendations_2013 <- docx_extract_all_tbls(recommendations_2013)
recommendations_2013 <- as_tibble(recommendations_2013[[1]])
recommendations_2013$Assessment.comments.on.level.of.implementation <- NULL
##removing all rows which start with "theme"
recommendations_2013 <-recommendations_2013 %>%
filter(!str_detect(Recommendation, 'Theme:'))
##splitting off first codes
y <-  colsplit(recommendations_2013$Recommendation," ",c("code","recommendations"))
##binding back together
recommendations_2013 <- cbind(recommendations_2013, y)
##dropping original column
recommendations_2013$Recommendation <- NULL
##use regex to remove ending redundant information from recommendations
##Source: https://r4ds.had.co.nz/strings.html
recommendations_2013$recommendations <- str_extract(recommendations_2013$recommendations, "(.*);")
##found one instance where a typo in punctuation removed the string
sum(is.na(recommendations_2013$recommendations))
##adding back in
line_49 <- "Develop programme for sharing of its experiences in addressing the right to development with African countries in the context of the Forum on China-Africa cooperation (Sierra Leone)"
recommendations_2013[49,4] <- line_49
##testing separating country comments
recommendations_2013 <- separate(recommendations_2013, col = recommendations, into = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k"), sep = ";", remove = FALSE)
##replacing empty strings with NA
recommendations_2013[recommendations_2013==""]<-NA
recommendations_2013$recommendations <- NULL
recommendations_2013 <- recommendations_2013 %>% pivot_longer(cols = a:k, values_to = "recommendations", values_drop_na = TRUE)
recommendations_2013$name <- NULL
?str_extract
recommendations_2013$country <- str_extract(recommendations_2013$recommendations, "(?<=\\().+?(?=\\))")
recommendations_2013$recommendations <- str_remove(recommendations_2013$recommendations, "\\([^()]*\\)")
View(recommendations_2013)
=======
>>>>>>> e231585f6bf8943abb1589d672e585dbc8fbf09f
